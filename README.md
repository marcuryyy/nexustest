# Запуск кода
1. Клонировать репозиторий ```git clone https://github.com/marcuryyy/nexustest```
2. Установить requirements.txt ```pip install -r requirements.txt```
3. В самом файле fit_and_predict.py снизу есть пример кода, как начать работу с классом.

**Важно**: Работает с файлами в формате .txt, предполагается, что текст в файлах на русском.

Чтобы работать с файлами формата docx, doc, odt и прочими, нужны соответствующие библиотеки.

Для быстрого старта уже есть директории для обучения и теста. Можно просто запустить код в том виде, в каком он есть сейчас и проверить работу.

# Директория для обучения:

![image](https://github.com/user-attachments/assets/9c061561-13b5-4600-ac4a-109a9a5fa46d)

# Директория для теста:

![image](https://github.com/user-attachments/assets/32edd629-389b-4107-96b8-cb298dd669cb)




# Задание
Пусть есть набор текстовых документов, разделенных на классы (например, лежащих в разных директориях) по смыслу (семантике). Классов может быть любое количество, в том числе переменное (то есть типы могут добавляться и удаляться). Необходимо написать классификатор таких документов по смыслу. Подсказка: используйте свойство расположения эмбеддингов в пространстве. Попробуйте различные инструменты для векторизации документов. В этом случае удобно сохранять ранее посчитанные эмбеддинги для известных документов. Рассчитайте для независимого набора (на котором модель не обучалась и для которого не сохранены эмбеддинги) данных долю верных предсказаний модели, если документа нет в известных модели эмбеддингов (некоторый порог выше определенного), то считайте документ неизвестным системе.

# Идея
Определимся с методом векторизации документов. Для решения данной задачи я использовал модель **rubert-tiny2** (**HuggingFace**: cointegrated/rubert-tiny2), которая использует механизм самовнимания, позволяющий учитывать контекст как слева, так и справа от слова. Использована модель обученная именно под русский текст, так как предполагается, что содержание документов на русском. Остальные характеристики можно прочитать по ссылке: https://huggingface.co/cointegrated/rubert-tiny2

Другие методы векторизации (например, **Bag of Words** или **TF-IDF**) я посчитал неподходящими для этой задачи, так как в обоих случаях получается очень большой вектор, что приведет к большим вычислительным сложностям и тратам памяти.

В целом, вместо данной модели в коде можно вписать ссылку на любую другую, которая есть на HuggingFace.

# Решение
Перед использованием **rubert-tiny2**, я проверил несколько других моделей, о которых была информация в документации Sentence Transformers:
https://huggingface.co/sentence-transformers/all-mpnet-base-v2 - модель от Microsoft, которая очень неплохо справляется со своей задачей, однако обучена только на английском языке.

https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v1
https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 - это мультиязыковые модели, которые поддерживают работу с русским языком. Однако в сравнении с rubert-tiny2 они проигрывают. Ниже будут приведены скрины, демонстрирующие вывод разных моделей.

Помимо этого, сам текст я предобрабатываю при помощи библиотеки **spacy**: очищаю от стоп-слов, знаков пунктуации, перевожу все слова в нижний регистр и ставлю их в начальную форму.

**Основной** класс - ClassificatorModel. При инициализации указываются: имя модели (с HuggingFace, например, cointegrated/rubert-tiny2), порог, с которого считаем, что документ незвестен системе, а также количество соседей для алгоритма kNN.

**Методы** класса:
**fit** - Метод для обучения модели. Считывает директорию с папками (т.е. классами) и текстовыми документами в них. Предобрабатывает их и считает эмбеддинги.

**predict** - Метод для предсказания меток классов новых документов. Получает на вход директорию с текстами. Предобрабатывает их и считает эмбеддинги. Далее проверка принадлежности к существующим классам происходит при помощи kNN. Берется точка нового документа, а также k ближайших соседей (их количество определяется атрибутом, заданном при инициализации объекта). Далее сравниваются расстояния до каждого из соседей с пороговым значением. Если расстояние меньше, то увеличиваем счетчик данного класса на 1, если больше - не трогаем. В конце концов у нас получается словарь вида "название класса": количество соседей, расстояние которых меньше порога. Из него мы достаем максимальное значение - это и будет предсказанный класс.

**score** - Метод для оценивания доли верно предсказанных меток классов. (!Зависит от порядка меток в массиве!)

Подробная информация об аргументах методов в самом коде.

# Тесты

В качестве мини базы с текстами я использовал новости с lenta.ru: https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.1/lenta-ru-news.csv.bz2

Три класса по 6 текстов и еще 6 текстов без классов (собственно, на котором и проверялась модель).

Тесты проводились при пороге 0.2 и количестве соседей равном 5.

**Результаты rubert-tiny2**:

![image](https://github.com/user-attachments/assets/47c1fe56-8411-43b9-bd67-1dbbb5e84ed8)

**Результаты distiluse-base-multilingual-cased-v1**

![image](https://github.com/user-attachments/assets/25cbab21-0910-489a-a2e8-6908653a303f)

**Результаты paraphrase-multilingual-MiniLM-L12-v2**

![image](https://github.com/user-attachments/assets/9120894a-f339-4913-a954-8a87770d0f59)






